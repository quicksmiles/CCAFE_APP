<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GWAS Case/Control Data Processing with Python and R Integration</title>
    <style>
        body {
            font-family: Arial, serif;
            line-height: 1.6;
            margin: 20px;
            padding: 0;
            color: #333;
        }
        h1, h2, h3, h4 {
            color: #0056b3;
        }
        pre, code {
            background-color: #f4f4f4;
            padding: 10px;
            border: 1px solid #ccc;
            margin: 10px 0;
            display: block;
        }
        .diagram {
            border: 1px solid #ccc;
            padding: 20px;
            margin: 20px 0;
            background-color: #f9f9f9;
        }
    </style>
</head>
<body>

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GWAS Case/Control Data Processing with Python and R Integration</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            padding: 0;
            line-height: 1.6;
            color: #333;
        }
        h1, h2, h3, h4 {
            color: #2C3E50;
        }
        ul, ol {
            margin: 20px 0;
            padding-left: 20px;
        }
        code, pre {
            background-color: #f4f4f4;
            padding: 10px;
            border: 1px solid #ccc;
            display: block;
        }
        .diagram {
            background-color: #f9f9f9;
            border: 1px solid #ccc;
            padding: 20px;
            margin-top: 20px;
        }
    </style>
</head>
<body>

    <h1>GWAS Data Processing with Python and R Integration</h1>

    <h2>1. Project Overview</h2>

    <h3>Title:</h3>
    <p>GWAS Data Processing with Python and R Integration</p>

    <h3>Objective:</h3>
    <p>The goal of this project is to create a system where users can upload a GWAS summary statistics file, and the system will query gnomAD for allele frequencies based on the "chromosome" and "position" variables. Once merged, R methods will be applied to the resulting table using Python as the orchestrating environment. All user data will be purged after processing to maintain privacy.</p>

    <h3>Scope:</h3>
    <ul>
        <li>Users upload GWAS files.</li>
        <li>Hail queries gnomAD for allele frequency data.</li>
        <li>Data merged on "chromosome" and "position".</li>
        <li>R methods are applied via rpy2 or script execution.</li>
        <li>Data purging post-processing.</li>
        <li>Docker Compose for deployment.</li>
        <li>Hosted on Google Cloud Platform (GCP) virtual machine.</li>
    </ul>

    <h2>2. Requirements</h2>

    <h3>Functional Requirements:</h3>
    <ul>
        <li>Users can upload a GWAS summary statistics file via a web interface.</li>
        <li>The program will query gnomAD for allele frequencies corresponding to the "chromosome" and "position" in the user's file.</li>
        <li>Data merging of the GWAS summary statistics file with the gnomAD allele frequencies based on matching "chromosome" and "position".</li>
        <li>R methods are applied to the merged data from within Python.</li>
        <li>After processing, the user’s data is securely deleted.</li>
        <li>The system runs within Docker containers, including one for the web server and one for task management.</li>
    </ul>

    <h3>Non-Functional Requirements:</h3>
    <ul>
        <li><strong>Security:</strong> All user data must be purged after the R methods have been applied.</li>
        <li><strong>Scalability:</strong> The system should handle large datasets from GWAS and gnomAD efficiently.</li>
        <li><strong>Resource Management:</strong> Constrain resources using Docker to ensure efficient usage on GCP.</li>
    </ul>

    <h3>Tech Stack:</h3>
    <ul>
        <li>Programming Languages: Python (Flask), R</li>
        <li>Libraries/Tools:
            <ul>
                <li>rpy2 for integrating R within Python.</li>
                <li>Hail for querying gnomAD.</li>
                <li>Docker Compose for containerization.</li>
            </ul>
        </li>
        <li>Hosting: Google Cloud Platform (GCP) Virtual Machine.</li>
    </ul>

    <h2>3. User Stories</h2>

    <ul>
        <li>As a researcher, I want to upload a GWAS summary statistics file and receive a merged file with allele frequencies from gnomAD so that I can perform further analysis.</li>
        <li>As a data scientist, I want the system to apply R methods to the merged data directly from Python, allowing me to leverage both languages for analysis.</li>
        <li>As a security-conscious user, I want my uploaded data to be deleted after processing to ensure privacy.</li>
    </ul>

    <h2>4. System Architecture</h2>

    <h3>High-Level Components:</h3>
    <ul>
        <li><strong>Web Server (Flask):</strong> Manages user uploads and handles requests. Runs in its own Docker container.</li>
        <li><strong>Hail/gnomAD Querying:</strong> Hail queries gnomAD for allele frequencies based on the "chromosome" and "position" variables. Merges this data with the user’s GWAS file.</li>
        <li><strong>R Method Execution (rpy2):</strong> The merged data is passed to R methods via rpy2 or script execution.</li>
        <li><strong>Task Queue (Celery/Redis):</strong> Runs the long-running tasks (querying gnomAD, merging, R processing) in the background. Runs in a separate Docker container for scalability.</li>
        <li><strong>Docker Compose:</strong> Orchestrates containers for web server and task queue.</li>
        <li><strong>Data Purge:</strong> Ensures all data related to the user’s GWAS file is purged after processing.</li>
    </ul>

    <h3>Data Flow:</h3>
    <ol>
        <li>User uploads GWAS summary.</li>
        <li>Hail queries gnomAD and returns allele frequencies.</li>
        <li>GWAS data and gnomAD data are merged.</li>
        <li>R methods are applied to the merged data using rpy2.</li>
        <li>Processed data is returned, and the uploaded data is deleted.</li>
    </ol>

    <div class="diagram">
        <h4>Architecture Diagram:</h4>
        <p>[Insert a diagram showing Flask (web server), Hail, R via rpy2, Docker Compose, and GCP].</p>
    </div>

    <h2>5. Data Structures and Algorithms</h2>

    <h3>Data Models:</h3>
    <ul>
        <li><strong>GWAS Summary File:</strong> Key Variables: chromosome, position, allele frequency, p-value, etc.</li>
        <li><strong>gnomAD Data:</strong> Key Variables: chromosome, position, allele frequency.</li>
        <li><strong>Merged Data:</strong> Combines GWAS data with gnomAD allele frequencies based on "chromosome" and "position".</li>
    </ul>

    <h3>Algorithms:</h3>
    <ul>
        <li><strong>Hail Querying:</strong> Efficiently queries gnomAD for chromosome/position pairs.</li>
        <li><strong>Merging Algorithm:</strong> Match GWAS records with gnomAD records based on chromosome/position pairs.</li>
        <li><strong>R Methods:</strong> R methods are applied via Python using rpy2 or script execution.</li>
    </ul>

    <h2>6. Development Roadmap</h2>

    <h3>Milestones:</h3>
    <ul>
        <li><strong>Phase 1: Project Setup</strong>
            <ul>
                <li>Set up Flask web server for file uploads.</li>
                <li>Set up Hail for querying gnomAD.</li>
            </ul>
        </li>
        <li><strong>Phase 2: Data Processing</strong>
            <ul>
                <li>Implement data merging between GWAS file and gnomAD results.</li>
                <li>Test R integration with rpy2 or R script execution.</li>
            </ul>
        </li>
        <li><strong>Phase 3: Docker and Deployment</strong>
            <ul>
                <li>Dockerize the application using Docker Compose.</li>
                <li>Deploy on GCP VM.</li>
            </ul>
        </li>
        <li><strong>Phase 4: Final Integration</strong>
            <ul>
                <li>Set up task queues using Celery/Redis.</li>
                <li>Ensure data purging functionality.</li>
            </ul>
        </li>
    </ul>

    <h3>Timeline:</h3>
    <ul>
        <li>Phase 1: 2 weeks</li>
        <li>Phase 2: 3 weeks</li>
        <li>Phase 3: 2 weeks</li>
        <li>Phase 4: 1 week</li>

    <p>This project involves building a system where users can upload GWAS summary statistics files, query allele frequencies from gnomAD using Hail, merge the data, and apply R-based methods within Python. The system architecture leverages task queues using Celery and Redis for handling asynchronous tasks, and Docker Compose for resource-efficient deployment. The project will run on a Google Cloud Platform virtual machine.</p>

    <h2>System Overview</h2>
    <p>The project consists of the following components:</p>
    <ul>
        <li>Flask web server to handle user file uploads and requests.</li>
        <li>Task queue system (Celery and Redis) to manage long-running tasks asynchronously.</li>
        <li>Hail queries to gnomAD for retrieving allele frequencies based on chromosome and position.</li>
        <li>R methods applied to merged GWAS and gnomAD data via rpy2 or script execution.</li>
        <li>Data purging after processing to ensure user privacy.</li>
        <li>Docker Compose for containerized deployment.</li>
    </ul>

    <h2>Key Components</h2>

    <h3>1. Flask Web Server</h3>
    <p>The web server will handle incoming user requests and manage file uploads. Once a user uploads their GWAS summary statistics file, it passes off the processing work to Celery workers.</p>

    <h3>2. Task Queue in System Architecture (Celery/Redis)</h3>
    <p>The <strong>task queue</strong> plays a critical role in managing long-running tasks, such as querying gnomAD, merging large datasets, and applying R methods, in an asynchronous manner. This allows the web server to remain responsive while handling potentially slow operations in the background.</p>

    <h4>Why Use a Task Queue?</h4>
    <p>In this project, querying gnomAD and merging large GWAS datasets can take considerable time, especially with larger files. Instead of blocking the web server while waiting for these tasks to complete, the task queue offloads them to a separate worker process. This ensures that the web server can continue to handle new user requests without being tied up by long operations.</p>

    <h3>How Celery and Redis Work Together</h3>

    <h4>Celery:</h4>
    <ul>
        <li><strong>Celery</strong> is a distributed task queue that allows Python functions to run asynchronously (in the background). It's used to handle heavy tasks (like data processing) outside the main web server process.</li>
        <li>In this system, Celery will be responsible for:
            <ul>
                <li>Running the Hail queries against gnomAD.</li>
                <li>Merging the GWAS and gnomAD data.</li>
                <li>Invoking R scripts to process the merged data.</li>
                <li>Deleting the user’s uploaded data after the task completes.</li>
            </ul>
        </li>
    </ul>

    <h4>Redis:</h4>
    <ul>
        <li><strong>Redis</strong> is used as a message broker for Celery. It stores messages (tasks) that need to be processed and ensures they are delivered to the right workers.</li>
        <li>Redis will handle the communication between the web server and the Celery workers, managing task queues, and ensuring tasks are executed in the background.</li>
    </ul>

    <h4>Flow of Task Execution:</h4>
    <ol>
        <li><strong>User Uploads GWAS File:</strong>  
        The web server receives the GWAS file and immediately delegates the heavy-lifting tasks (e.g., querying gnomAD, merging, running R methods) to Celery.</li>
        <li><strong>Celery Worker Picks Up the Task:</strong>  
        The task (querying gnomAD, merging files, running R methods) is placed in the task queue (Redis). A Celery worker picks up the task and starts processing it in the background.</li>
        <li><strong>Task Execution:</strong>  
        The worker executes the task in the background, such as fetching data from gnomAD, merging it with the GWAS file, and applying R methods.</li>
        <li><strong>Result Returned:</strong>  
        Once the task is complete, the result is either stored temporarily or returned to the web server to be sent back to the user. Afterward, the user's data is purged.</li>
        <li><strong>Data Purging:</strong>  
        After the R methods are applied and the output is returned to the user, the worker deletes the user’s data from the system to ensure privacy.</li>
    </ol>

    <h3>3. R Method Execution via Scripts</h3>
    <p>The <strong>integration of R methods</strong> within Python will rely on either:</p>
    <ul>
        <li><strong>rpy2</strong> (for direct R calls in Python).</li>
        <li><strong>Executing R Scripts</strong> via subprocess calls from Python.</li>
    </ul>

    <h4>Why Use R Scripts?</h4>
    <p>Although rpy2 provides a direct interface to call R functions from Python, there are situations where:</p>
    <ul>
        <li>The R environment may be complex (e.g., specific R libraries that are easier to run in an isolated script).</li>
        <li>Certain tasks may be better organized in standalone scripts for better modularity, easier debugging, or reuse.</li>
    </ul>

    <h4>Steps to Implement R Scripts in Python:</h4>
    <ol>
        <li><strong>Prepare the Merged Data:</strong>  
        After merging the GWAS and gnomAD data, save the resulting data to a CSV or a similar format that can be passed to the R script.</li>
        <li><strong>Trigger R Script Execution:</strong>  
        Use Python’s <code>subprocess</code> module to call R scripts. Example:
        <pre><code>import subprocess
result = subprocess.run(["Rscript", "my_script.R", "input_data.csv", "output_data.csv"], capture_output=True)</code></pre>
        </li>
        <li><strong>Process the Output:</strong>  
        After the R script completes, the resulting data can be loaded back into Python for further use or returned to the user.</li>
        <li><strong>Data Cleanup:</strong>  
        Ensure that after the R script finishes, both the input (uploaded data) and any temporary files are deleted from the system.</li>
    </ol>
